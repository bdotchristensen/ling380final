{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, TFBertModel, pipeline\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Russian, Polish, Finnish, Czech, German"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uncased</th>\n",
       "      <th>genitive</th>\n",
       "      <th>dative</th>\n",
       "      <th>accusative</th>\n",
       "      <th>instrumental</th>\n",
       "      <th>prepositional</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>человек</td>\n",
       "      <td>человека</td>\n",
       "      <td>человеку</td>\n",
       "      <td>человека</td>\n",
       "      <td>человеком</td>\n",
       "      <td>человеке</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>время</td>\n",
       "      <td>времени</td>\n",
       "      <td>времени</td>\n",
       "      <td>время</td>\n",
       "      <td>временем</td>\n",
       "      <td>времени</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>рука</td>\n",
       "      <td>руки</td>\n",
       "      <td>руке</td>\n",
       "      <td>руку</td>\n",
       "      <td>рукой</td>\n",
       "      <td>руке</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>дело</td>\n",
       "      <td>дела</td>\n",
       "      <td>делу</td>\n",
       "      <td>дело</td>\n",
       "      <td>делом</td>\n",
       "      <td>деле</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>день</td>\n",
       "      <td>дня</td>\n",
       "      <td>дню</td>\n",
       "      <td>день</td>\n",
       "      <td>днём</td>\n",
       "      <td>дне</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1794</th>\n",
       "      <td>Рим</td>\n",
       "      <td>Рима</td>\n",
       "      <td>Риму</td>\n",
       "      <td>Рим</td>\n",
       "      <td>Римом</td>\n",
       "      <td>Риме</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1795</th>\n",
       "      <td>жилец</td>\n",
       "      <td>жильца</td>\n",
       "      <td>жильцу</td>\n",
       "      <td>жильца</td>\n",
       "      <td>жильцом</td>\n",
       "      <td>жильце</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1796</th>\n",
       "      <td>обсуждение</td>\n",
       "      <td>обсуждения</td>\n",
       "      <td>обсуждению</td>\n",
       "      <td>обсуждение</td>\n",
       "      <td>обсуждением</td>\n",
       "      <td>обсуждении</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1797</th>\n",
       "      <td>заря</td>\n",
       "      <td>зари</td>\n",
       "      <td>заре</td>\n",
       "      <td>зарю</td>\n",
       "      <td>зарёй</td>\n",
       "      <td>заре</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1798</th>\n",
       "      <td>разработка</td>\n",
       "      <td>разработки</td>\n",
       "      <td>разработке</td>\n",
       "      <td>разработку</td>\n",
       "      <td>разработкой</td>\n",
       "      <td>разработке</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1799 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         uncased    genitive      dative  accusative instrumental  \\\n",
       "0        человек    человека    человеку    человека    человеком   \n",
       "1          время     времени     времени       время     временем   \n",
       "2           рука        руки        руке        руку        рукой   \n",
       "3           дело        дела        делу        дело        делом   \n",
       "4           день         дня         дню        день         днём   \n",
       "...          ...         ...         ...         ...          ...   \n",
       "1794         Рим        Рима        Риму         Рим        Римом   \n",
       "1795       жилец      жильца      жильцу      жильца      жильцом   \n",
       "1796  обсуждение  обсуждения  обсуждению  обсуждение  обсуждением   \n",
       "1797        заря        зари        заре        зарю        зарёй   \n",
       "1798  разработка  разработки  разработке  разработку  разработкой   \n",
       "\n",
       "     prepositional  \n",
       "0         человеке  \n",
       "1          времени  \n",
       "2             руке  \n",
       "3             деле  \n",
       "4              дне  \n",
       "...            ...  \n",
       "1794          Риме  \n",
       "1795        жильце  \n",
       "1796    обсуждении  \n",
       "1797          заре  \n",
       "1798    разработке  \n",
       "\n",
       "[1799 rows x 6 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ru = pd.read_csv('./Slavic-BERT-NER/russian_nouns_cased.csv', index_col = 0)\n",
    "ru"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uncased</th>\n",
       "      <th>nominative</th>\n",
       "      <th>genitive</th>\n",
       "      <th>dative</th>\n",
       "      <th>accusative</th>\n",
       "      <th>instrumental</th>\n",
       "      <th>locative</th>\n",
       "      <th>vocative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mama</td>\n",
       "      <td>mama</td>\n",
       "      <td>mamy</td>\n",
       "      <td>mamie</td>\n",
       "      <td>mamę</td>\n",
       "      <td>mamą</td>\n",
       "      <td>mamie</td>\n",
       "      <td>mamo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pan</td>\n",
       "      <td>pan</td>\n",
       "      <td>pana</td>\n",
       "      <td>panu</td>\n",
       "      <td>pana</td>\n",
       "      <td>panem</td>\n",
       "      <td>panie</td>\n",
       "      <td>panie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>więc</td>\n",
       "      <td>wiec</td>\n",
       "      <td>wiecu</td>\n",
       "      <td>wiecowi</td>\n",
       "      <td>wiec</td>\n",
       "      <td>wiecem</td>\n",
       "      <td>wiecu</td>\n",
       "      <td>wiecu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pani</td>\n",
       "      <td>pani</td>\n",
       "      <td>pani</td>\n",
       "      <td>pani</td>\n",
       "      <td>panią</td>\n",
       "      <td>panią</td>\n",
       "      <td>pani</td>\n",
       "      <td>pani!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>żeby</td>\n",
       "      <td>ząb</td>\n",
       "      <td>zęba</td>\n",
       "      <td>zębowi</td>\n",
       "      <td>ząb</td>\n",
       "      <td>zębem</td>\n",
       "      <td>zębie</td>\n",
       "      <td>zębie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1678</th>\n",
       "      <td>organizacja</td>\n",
       "      <td>organizacja</td>\n",
       "      <td>organizacji</td>\n",
       "      <td>organizacji</td>\n",
       "      <td>organizację</td>\n",
       "      <td>organizacją</td>\n",
       "      <td>organizacji</td>\n",
       "      <td>organizacjo!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1680</th>\n",
       "      <td>wąż</td>\n",
       "      <td>wąż</td>\n",
       "      <td>węża</td>\n",
       "      <td>wężowi</td>\n",
       "      <td>węża</td>\n",
       "      <td>wężem</td>\n",
       "      <td>wężu</td>\n",
       "      <td>wężu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1681</th>\n",
       "      <td>banda</td>\n",
       "      <td>banda</td>\n",
       "      <td>bandy</td>\n",
       "      <td>bandzie</td>\n",
       "      <td>bandę</td>\n",
       "      <td>bandą</td>\n",
       "      <td>bandzie</td>\n",
       "      <td>bando</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1682</th>\n",
       "      <td>chleb</td>\n",
       "      <td>chleb</td>\n",
       "      <td>chleba</td>\n",
       "      <td>chlebowi</td>\n",
       "      <td>chleb</td>\n",
       "      <td>chlebem</td>\n",
       "      <td>chlebie</td>\n",
       "      <td>chlebie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1684</th>\n",
       "      <td>ćwiczenie</td>\n",
       "      <td>ćwiczenie</td>\n",
       "      <td>ćwiczenia</td>\n",
       "      <td>ćwiczeniu</td>\n",
       "      <td>ćwiczenie</td>\n",
       "      <td>ćwiczeniem</td>\n",
       "      <td>ćwiczeniu</td>\n",
       "      <td>ćwiczenie</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>816 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          uncased   nominative     genitive       dative   accusative  \\\n",
       "0            mama         mama         mamy        mamie         mamę   \n",
       "1             pan          pan         pana         panu         pana   \n",
       "2            więc         wiec        wiecu      wiecowi         wiec   \n",
       "3            pani         pani         pani         pani        panią   \n",
       "4            żeby          ząb         zęba       zębowi          ząb   \n",
       "...           ...          ...          ...          ...          ...   \n",
       "1678  organizacja  organizacja  organizacji  organizacji  organizację   \n",
       "1680          wąż          wąż         węża       wężowi         węża   \n",
       "1681        banda        banda        bandy      bandzie        bandę   \n",
       "1682        chleb        chleb       chleba     chlebowi        chleb   \n",
       "1684    ćwiczenie    ćwiczenie    ćwiczenia    ćwiczeniu    ćwiczenie   \n",
       "\n",
       "     instrumental     locative      vocative  \n",
       "0            mamą        mamie          mamo  \n",
       "1           panem        panie         panie  \n",
       "2          wiecem        wiecu         wiecu  \n",
       "3           panią         pani         pani!  \n",
       "4           zębem        zębie         zębie  \n",
       "...           ...          ...           ...  \n",
       "1678  organizacją  organizacji  organizacjo!  \n",
       "1680        wężem         wężu          wężu  \n",
       "1681        bandą      bandzie         bando  \n",
       "1682      chlebem      chlebie       chlebie  \n",
       "1684   ćwiczeniem    ćwiczeniu     ćwiczenie  \n",
       "\n",
       "[816 rows x 8 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pl = pd.read_csv('./Slavic-BERT-NER/polish_nouns_cased.csv', index_col = 0)\n",
    "pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Nominative</th>\n",
       "      <th>accusative_nom</th>\n",
       "      <th>accusative_gen</th>\n",
       "      <th>genitive</th>\n",
       "      <th>partitive</th>\n",
       "      <th>inessive</th>\n",
       "      <th>elative</th>\n",
       "      <th>illative</th>\n",
       "      <th>adessive</th>\n",
       "      <th>ablative</th>\n",
       "      <th>allative</th>\n",
       "      <th>essive</th>\n",
       "      <th>translative</th>\n",
       "      <th>abessive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vuosi</td>\n",
       "      <td>vuosi</td>\n",
       "      <td>vuoden</td>\n",
       "      <td>vuoden</td>\n",
       "      <td>vuotta</td>\n",
       "      <td>vuodessa</td>\n",
       "      <td>vuodesta</td>\n",
       "      <td>vuoteen</td>\n",
       "      <td>vuodella</td>\n",
       "      <td>vuodelta</td>\n",
       "      <td>vuodelle</td>\n",
       "      <td>vuotena</td>\n",
       "      <td>vuodeksi</td>\n",
       "      <td>vuodetta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>markka</td>\n",
       "      <td>markka</td>\n",
       "      <td>markan</td>\n",
       "      <td>markan</td>\n",
       "      <td>markkaa</td>\n",
       "      <td>markassa</td>\n",
       "      <td>markasta</td>\n",
       "      <td>markkaan</td>\n",
       "      <td>markalla</td>\n",
       "      <td>markalta</td>\n",
       "      <td>markalle</td>\n",
       "      <td>markkana</td>\n",
       "      <td>markaksi</td>\n",
       "      <td>markatta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>maa</td>\n",
       "      <td>maa</td>\n",
       "      <td>maan</td>\n",
       "      <td>maan</td>\n",
       "      <td>maata</td>\n",
       "      <td>maassa</td>\n",
       "      <td>maasta</td>\n",
       "      <td>maahan</td>\n",
       "      <td>maalla</td>\n",
       "      <td>maalta</td>\n",
       "      <td>maalle</td>\n",
       "      <td>maana</td>\n",
       "      <td>maaksi</td>\n",
       "      <td>maatta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>asia</td>\n",
       "      <td>asia</td>\n",
       "      <td>asian</td>\n",
       "      <td>asian</td>\n",
       "      <td>asiaa</td>\n",
       "      <td>asiassa</td>\n",
       "      <td>asiasta</td>\n",
       "      <td>asiaan</td>\n",
       "      <td>asialla</td>\n",
       "      <td>asialta</td>\n",
       "      <td>asialle</td>\n",
       "      <td>asiana</td>\n",
       "      <td>asiaksi</td>\n",
       "      <td>asiatta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>prosentti</td>\n",
       "      <td>prosentti</td>\n",
       "      <td>prosentin</td>\n",
       "      <td>prosentin</td>\n",
       "      <td>prosenttia</td>\n",
       "      <td>prosentissa</td>\n",
       "      <td>prosentista</td>\n",
       "      <td>prosenttiin</td>\n",
       "      <td>prosentilla</td>\n",
       "      <td>prosentilta</td>\n",
       "      <td>prosentille</td>\n",
       "      <td>prosenttina</td>\n",
       "      <td>prosentiksi</td>\n",
       "      <td>prosentitta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2045</th>\n",
       "      <td>lemmikki</td>\n",
       "      <td>lemmikki</td>\n",
       "      <td>lemmikin</td>\n",
       "      <td>lemmikin</td>\n",
       "      <td>lemmikkiä</td>\n",
       "      <td>lemmikissä</td>\n",
       "      <td>lemmikistä</td>\n",
       "      <td>lemmikkiin</td>\n",
       "      <td>lemmikillä</td>\n",
       "      <td>lemmikiltä</td>\n",
       "      <td>lemmikille</td>\n",
       "      <td>lemmikkinä</td>\n",
       "      <td>lemmikiksi</td>\n",
       "      <td>lemmikittä</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2046</th>\n",
       "      <td>porkkana</td>\n",
       "      <td>porkkana</td>\n",
       "      <td>porkkanan</td>\n",
       "      <td>porkkanan</td>\n",
       "      <td>porkkanaa</td>\n",
       "      <td>porkkanassa</td>\n",
       "      <td>porkkanasta</td>\n",
       "      <td>porkkanaan</td>\n",
       "      <td>porkkanalla</td>\n",
       "      <td>porkkanalta</td>\n",
       "      <td>porkkanalle</td>\n",
       "      <td>porkkanana</td>\n",
       "      <td>porkkanaksi</td>\n",
       "      <td>porkkanatta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2047</th>\n",
       "      <td>syrjä</td>\n",
       "      <td>syrjä</td>\n",
       "      <td>syrjän</td>\n",
       "      <td>syrjän</td>\n",
       "      <td>syrjää</td>\n",
       "      <td>syrjässä</td>\n",
       "      <td>syrjästä</td>\n",
       "      <td>syrjään</td>\n",
       "      <td>syrjällä</td>\n",
       "      <td>syrjältä</td>\n",
       "      <td>syrjälle</td>\n",
       "      <td>syrjänä</td>\n",
       "      <td>syrjäksi</td>\n",
       "      <td>syrjättä</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2048</th>\n",
       "      <td>eurooppalainen</td>\n",
       "      <td>eurooppalainen</td>\n",
       "      <td>eurooppalaisen</td>\n",
       "      <td>eurooppalaisen</td>\n",
       "      <td>eurooppalaista</td>\n",
       "      <td>eurooppalaisessa</td>\n",
       "      <td>eurooppalaisesta</td>\n",
       "      <td>eurooppalaiseen</td>\n",
       "      <td>eurooppalaisella</td>\n",
       "      <td>eurooppalaiselta</td>\n",
       "      <td>eurooppalaiselle</td>\n",
       "      <td>eurooppalaisena</td>\n",
       "      <td>eurooppalaiseksi</td>\n",
       "      <td>eurooppalaisetta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2049</th>\n",
       "      <td>kansanpuolue</td>\n",
       "      <td>kansanpuolue</td>\n",
       "      <td>kansanpuolueen</td>\n",
       "      <td>kansanpuolueen</td>\n",
       "      <td>kansanpuoluetta</td>\n",
       "      <td>kansanpuolueessa</td>\n",
       "      <td>kansanpuolueesta</td>\n",
       "      <td>kansanpuolueeseen</td>\n",
       "      <td>kansanpuolueella</td>\n",
       "      <td>kansanpuolueelta</td>\n",
       "      <td>kansanpuolueelle</td>\n",
       "      <td>kansanpuolueena</td>\n",
       "      <td>kansanpuolueeksi</td>\n",
       "      <td>kansanpuolueetta</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2050 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Nominative  accusative_nom  accusative_gen        genitive  \\\n",
       "0              vuosi           vuosi          vuoden          vuoden   \n",
       "1             markka          markka          markan          markan   \n",
       "2                maa             maa            maan            maan   \n",
       "3               asia            asia           asian           asian   \n",
       "4          prosentti       prosentti       prosentin       prosentin   \n",
       "...              ...             ...             ...             ...   \n",
       "2045        lemmikki        lemmikki        lemmikin        lemmikin   \n",
       "2046        porkkana        porkkana       porkkanan       porkkanan   \n",
       "2047           syrjä           syrjä          syrjän          syrjän   \n",
       "2048  eurooppalainen  eurooppalainen  eurooppalaisen  eurooppalaisen   \n",
       "2049    kansanpuolue    kansanpuolue  kansanpuolueen  kansanpuolueen   \n",
       "\n",
       "            partitive          inessive           elative           illative  \\\n",
       "0              vuotta          vuodessa          vuodesta            vuoteen   \n",
       "1             markkaa          markassa          markasta           markkaan   \n",
       "2               maata            maassa            maasta             maahan   \n",
       "3               asiaa           asiassa           asiasta             asiaan   \n",
       "4          prosenttia       prosentissa       prosentista        prosenttiin   \n",
       "...               ...               ...               ...                ...   \n",
       "2045        lemmikkiä        lemmikissä        lemmikistä         lemmikkiin   \n",
       "2046        porkkanaa       porkkanassa       porkkanasta         porkkanaan   \n",
       "2047           syrjää          syrjässä          syrjästä            syrjään   \n",
       "2048   eurooppalaista  eurooppalaisessa  eurooppalaisesta    eurooppalaiseen   \n",
       "2049  kansanpuoluetta  kansanpuolueessa  kansanpuolueesta  kansanpuolueeseen   \n",
       "\n",
       "              adessive          ablative          allative           essive  \\\n",
       "0             vuodella          vuodelta          vuodelle          vuotena   \n",
       "1             markalla          markalta          markalle         markkana   \n",
       "2               maalla            maalta            maalle            maana   \n",
       "3              asialla           asialta           asialle           asiana   \n",
       "4          prosentilla       prosentilta       prosentille      prosenttina   \n",
       "...                ...               ...               ...              ...   \n",
       "2045        lemmikillä        lemmikiltä        lemmikille       lemmikkinä   \n",
       "2046       porkkanalla       porkkanalta       porkkanalle       porkkanana   \n",
       "2047          syrjällä          syrjältä          syrjälle          syrjänä   \n",
       "2048  eurooppalaisella  eurooppalaiselta  eurooppalaiselle  eurooppalaisena   \n",
       "2049  kansanpuolueella  kansanpuolueelta  kansanpuolueelle  kansanpuolueena   \n",
       "\n",
       "           translative          abessive  \n",
       "0             vuodeksi          vuodetta  \n",
       "1             markaksi          markatta  \n",
       "2               maaksi            maatta  \n",
       "3              asiaksi           asiatta  \n",
       "4          prosentiksi       prosentitta  \n",
       "...                ...               ...  \n",
       "2045        lemmikiksi        lemmikittä  \n",
       "2046       porkkanaksi       porkkanatta  \n",
       "2047          syrjäksi          syrjättä  \n",
       "2048  eurooppalaiseksi  eurooppalaisetta  \n",
       "2049  kansanpuolueeksi  kansanpuolueetta  \n",
       "\n",
       "[2050 rows x 14 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fi = pd.read_csv('./Slavic-BERT-NER/finnish_nouns_cased.csv', index_col = 0)\n",
    "fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nominative</th>\n",
       "      <th>genitive</th>\n",
       "      <th>dative</th>\n",
       "      <th>accusative</th>\n",
       "      <th>vocative</th>\n",
       "      <th>locative</th>\n",
       "      <th>instrumental</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rok</td>\n",
       "      <td>roka</td>\n",
       "      <td>roku</td>\n",
       "      <td>rok</td>\n",
       "      <td>roku</td>\n",
       "      <td>roku</td>\n",
       "      <td>rokem</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>člověk</td>\n",
       "      <td>člověka</td>\n",
       "      <td>člověku</td>\n",
       "      <td>člověka</td>\n",
       "      <td>člověče</td>\n",
       "      <td>člověku</td>\n",
       "      <td>člověkem</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>den</td>\n",
       "      <td>dne</td>\n",
       "      <td>dni</td>\n",
       "      <td>den</td>\n",
       "      <td>dne</td>\n",
       "      <td>dni</td>\n",
       "      <td>dnem</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>doba</td>\n",
       "      <td>doby</td>\n",
       "      <td>době</td>\n",
       "      <td>dobu</td>\n",
       "      <td>dobo</td>\n",
       "      <td>době</td>\n",
       "      <td>dobou</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dítě</td>\n",
       "      <td>dítěte</td>\n",
       "      <td>dítěti</td>\n",
       "      <td>dítě</td>\n",
       "      <td>dítě</td>\n",
       "      <td>dítěti</td>\n",
       "      <td>dítětem</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1569</th>\n",
       "      <td>platforma</td>\n",
       "      <td>platformy</td>\n",
       "      <td>platformě</td>\n",
       "      <td>platformu</td>\n",
       "      <td>platformo</td>\n",
       "      <td>platformě</td>\n",
       "      <td>platformou</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1570</th>\n",
       "      <td>skladatel</td>\n",
       "      <td>skladatele</td>\n",
       "      <td>skladateli</td>\n",
       "      <td>skladatele</td>\n",
       "      <td>skladateli</td>\n",
       "      <td>skladateli</td>\n",
       "      <td>skladatelem</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1571</th>\n",
       "      <td>náznak</td>\n",
       "      <td>náznaku</td>\n",
       "      <td>náznaku</td>\n",
       "      <td>náznak</td>\n",
       "      <td>náznaku</td>\n",
       "      <td>náznaku</td>\n",
       "      <td>náznakem</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1572</th>\n",
       "      <td>eurozóna</td>\n",
       "      <td>eurozóny</td>\n",
       "      <td>eurozóně</td>\n",
       "      <td>eurozónu</td>\n",
       "      <td>eurozóno</td>\n",
       "      <td>eurozóně</td>\n",
       "      <td>eurozónou</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1573</th>\n",
       "      <td>práh</td>\n",
       "      <td>prahu</td>\n",
       "      <td>prahu</td>\n",
       "      <td>práh</td>\n",
       "      <td>prahu</td>\n",
       "      <td>prahu</td>\n",
       "      <td>prahem</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1574 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     nominative    genitive      dative  accusative    vocative    locative  \\\n",
       "0           rok        roka        roku         rok        roku        roku   \n",
       "1        člověk     člověka     člověku     člověka     člověče     člověku   \n",
       "2           den         dne         dni         den         dne         dni   \n",
       "3          doba        doby        době        dobu        dobo        době   \n",
       "4          dítě      dítěte      dítěti        dítě        dítě      dítěti   \n",
       "...         ...         ...         ...         ...         ...         ...   \n",
       "1569  platforma   platformy   platformě   platformu   platformo   platformě   \n",
       "1570  skladatel  skladatele  skladateli  skladatele  skladateli  skladateli   \n",
       "1571     náznak     náznaku     náznaku      náznak     náznaku     náznaku   \n",
       "1572   eurozóna    eurozóny    eurozóně    eurozónu    eurozóno    eurozóně   \n",
       "1573       práh       prahu       prahu        práh       prahu       prahu   \n",
       "\n",
       "     instrumental  \n",
       "0           rokem  \n",
       "1        člověkem  \n",
       "2            dnem  \n",
       "3           dobou  \n",
       "4         dítětem  \n",
       "...           ...  \n",
       "1569   platformou  \n",
       "1570  skladatelem  \n",
       "1571     náznakem  \n",
       "1572    eurozónou  \n",
       "1573       prahem  \n",
       "\n",
       "[1574 rows x 7 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cz = pd.read_csv('./Slavic-BERT-NER/czech_nouns_cased.csv', index_col = 0)\n",
    "cz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>noun</th>\n",
       "      <th>lemma</th>\n",
       "      <th>pos</th>\n",
       "      <th>genus</th>\n",
       "      <th>genitiv singular</th>\n",
       "      <th>genitiv plural</th>\n",
       "      <th>dativ singular</th>\n",
       "      <th>dativ plural</th>\n",
       "      <th>akkusativ singular</th>\n",
       "      <th>akkusativ plural</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sie</td>\n",
       "      <td>Sie</td>\n",
       "      <td>Substantiv</td>\n",
       "      <td>f</td>\n",
       "      <td>Sie</td>\n",
       "      <td>Sie</td>\n",
       "      <td>Sie</td>\n",
       "      <td>Sie</td>\n",
       "      <td>Sie</td>\n",
       "      <td>Sie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sie</td>\n",
       "      <td>Sie</td>\n",
       "      <td>Substantiv</td>\n",
       "      <td>m</td>\n",
       "      <td>Sies</td>\n",
       "      <td>Sie</td>\n",
       "      <td>Sie</td>\n",
       "      <td>Sies</td>\n",
       "      <td>Sie</td>\n",
       "      <td>Sies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Es</td>\n",
       "      <td>Es</td>\n",
       "      <td>Substantiv</td>\n",
       "      <td>n</td>\n",
       "      <td>Es</td>\n",
       "      <td>Es</td>\n",
       "      <td>Es</td>\n",
       "      <td>Es</td>\n",
       "      <td>Es</td>\n",
       "      <td>Es</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Er</td>\n",
       "      <td>Er</td>\n",
       "      <td>Substantiv</td>\n",
       "      <td>m</td>\n",
       "      <td>Er</td>\n",
       "      <td>Er</td>\n",
       "      <td>Er</td>\n",
       "      <td>Er</td>\n",
       "      <td>Er</td>\n",
       "      <td>Er</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Zeit</td>\n",
       "      <td>Zeit</td>\n",
       "      <td>Substantiv</td>\n",
       "      <td>f</td>\n",
       "      <td>Zeit</td>\n",
       "      <td>Zeiten</td>\n",
       "      <td>Zeit</td>\n",
       "      <td>Zeiten</td>\n",
       "      <td>Zeit</td>\n",
       "      <td>Zeiten</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3538</th>\n",
       "      <td>Apotheke</td>\n",
       "      <td>Apotheke</td>\n",
       "      <td>Substantiv</td>\n",
       "      <td>f</td>\n",
       "      <td>Apotheke</td>\n",
       "      <td>Apotheken</td>\n",
       "      <td>Apotheke</td>\n",
       "      <td>Apotheken</td>\n",
       "      <td>Apotheke</td>\n",
       "      <td>Apotheken</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3539</th>\n",
       "      <td>Wood</td>\n",
       "      <td>Wood</td>\n",
       "      <td>Substantiv</td>\n",
       "      <td>m</td>\n",
       "      <td>Woods</td>\n",
       "      <td>Woods</td>\n",
       "      <td>Wood</td>\n",
       "      <td>Woods</td>\n",
       "      <td>Wood</td>\n",
       "      <td>Woods</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3540</th>\n",
       "      <td>Wecker</td>\n",
       "      <td>Wecker</td>\n",
       "      <td>Substantiv</td>\n",
       "      <td>m</td>\n",
       "      <td>Weckers</td>\n",
       "      <td>Wecker</td>\n",
       "      <td>Wecker</td>\n",
       "      <td>Weckern</td>\n",
       "      <td>Wecker</td>\n",
       "      <td>Wecker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3542</th>\n",
       "      <td>Unterwelt</td>\n",
       "      <td>Unterwelt</td>\n",
       "      <td>Substantiv</td>\n",
       "      <td>f</td>\n",
       "      <td>Unterwelt</td>\n",
       "      <td>Unterwelten</td>\n",
       "      <td>Unterwelt</td>\n",
       "      <td>Unterwelten</td>\n",
       "      <td>Unterwelt</td>\n",
       "      <td>Unterwelten</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3543</th>\n",
       "      <td>Union</td>\n",
       "      <td>Union</td>\n",
       "      <td>Substantiv</td>\n",
       "      <td>f</td>\n",
       "      <td>Union</td>\n",
       "      <td>Unionen</td>\n",
       "      <td>Union</td>\n",
       "      <td>Unionen</td>\n",
       "      <td>Union</td>\n",
       "      <td>Unionen</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2369 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           noun      lemma         pos genus genitiv singular genitiv plural  \\\n",
       "1           Sie        Sie  Substantiv     f              Sie            Sie   \n",
       "2           Sie        Sie  Substantiv     m             Sies            Sie   \n",
       "6            Es         Es  Substantiv     n               Es             Es   \n",
       "8            Er         Er  Substantiv     m               Er             Er   \n",
       "17         Zeit       Zeit  Substantiv     f             Zeit         Zeiten   \n",
       "...         ...        ...         ...   ...              ...            ...   \n",
       "3538   Apotheke   Apotheke  Substantiv     f         Apotheke      Apotheken   \n",
       "3539       Wood       Wood  Substantiv     m            Woods          Woods   \n",
       "3540     Wecker     Wecker  Substantiv     m          Weckers         Wecker   \n",
       "3542  Unterwelt  Unterwelt  Substantiv     f        Unterwelt    Unterwelten   \n",
       "3543      Union      Union  Substantiv     f            Union        Unionen   \n",
       "\n",
       "     dativ singular dativ plural akkusativ singular akkusativ plural  \n",
       "1               Sie          Sie                Sie              Sie  \n",
       "2               Sie         Sies                Sie             Sies  \n",
       "6                Es           Es                 Es               Es  \n",
       "8                Er           Er                 Er               Er  \n",
       "17             Zeit       Zeiten               Zeit           Zeiten  \n",
       "...             ...          ...                ...              ...  \n",
       "3538       Apotheke    Apotheken           Apotheke        Apotheken  \n",
       "3539           Wood        Woods               Wood            Woods  \n",
       "3540         Wecker      Weckern             Wecker           Wecker  \n",
       "3542      Unterwelt  Unterwelten          Unterwelt      Unterwelten  \n",
       "3543          Union      Unionen              Union          Unionen  \n",
       "\n",
       "[2369 rows x 10 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "de = pd.read_csv('./german/german_nouns_labeled', index_col = 0)\n",
    "de"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Russian preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at bert-base-multilingual-cased were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n",
      "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-multilingual-cased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')\n",
    "model = TFBertModel.from_pretrained(\"bert-base-multilingual-cased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150\n",
      "300\n",
      "450\n",
      "600\n",
      "750\n",
      "900\n",
      "1050\n",
      "1200\n",
      "1350\n",
      "1500\n",
      "1650\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1799, 768)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ru_unc = []\n",
    "\n",
    "for x in ru['uncased']:\n",
    "    \n",
    "    encoded_input_ru = tokenizer(x, return_tensors = 'tf')\n",
    "    output_ru = model(encoded_input_ru)\n",
    "    \n",
    "    ru_unc.append(tf.reduce_mean(output_ru.last_hidden_state, axis = 1))\n",
    "    \n",
    "    if len(ru_unc) % 150 == 0:\n",
    "        print(len(ru_unc))\n",
    "        \n",
    "ru_unc = np.array([x.numpy() for x in ru_unc])\n",
    "ru_unc = ru_unc.squeeze()\n",
    "ru_unc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150\n",
      "300\n",
      "450\n",
      "600\n",
      "750\n",
      "900\n",
      "1050\n",
      "1200\n",
      "1350\n",
      "1500\n",
      "1650\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1799, 768)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ru_acc = []\n",
    "\n",
    "for x in ru['accusative']:\n",
    "    \n",
    "    encoded_input_ru = tokenizer(x, return_tensors = 'tf')\n",
    "    output_ru = model(encoded_input_ru)\n",
    "    \n",
    "    ru_acc.append(tf.reduce_mean(output_ru.last_hidden_state, axis = 1))\n",
    "    \n",
    "    if len(ru_acc) % 150 == 0:\n",
    "        print(len(ru_acc))\n",
    "        \n",
    "ru_acc = np.array([x.numpy() for x in ru_acc])\n",
    "ru_acc = ru_acc.squeeze()\n",
    "ru_acc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150\n",
      "300\n",
      "450\n",
      "600\n",
      "750\n",
      "900\n",
      "1050\n",
      "1200\n",
      "1350\n",
      "1500\n",
      "1650\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1799, 768)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ru_dat = []\n",
    "\n",
    "for x in ru['dative']:\n",
    "    \n",
    "    encoded_input_ru = tokenizer(x, return_tensors = 'tf')\n",
    "    output_ru = model(encoded_input_ru)\n",
    "    \n",
    "    ru_dat.append(tf.reduce_mean(output_ru.last_hidden_state, axis = 1))\n",
    "    \n",
    "    if len(ru_dat) % 150 == 0:\n",
    "        print(len(ru_dat))\n",
    "        \n",
    "ru_dat = np.array([x.numpy() for x in ru_dat])\n",
    "ru_dat = ru_dat.squeeze()\n",
    "ru_dat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150\n",
      "300\n",
      "450\n",
      "600\n",
      "750\n",
      "900\n",
      "1050\n",
      "1200\n",
      "1350\n",
      "1500\n",
      "1650\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1799, 768)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ru_gen = []\n",
    "\n",
    "for x in ru['genitive']:\n",
    "    \n",
    "    encoded_input_ru = tokenizer(x, return_tensors = 'tf')\n",
    "    output_ru = model(encoded_input_ru)\n",
    "    \n",
    "    ru_gen.append(tf.reduce_mean(output_ru.last_hidden_state, axis = 1))\n",
    "    \n",
    "    if len(ru_gen) % 150 == 0:\n",
    "        print(len(ru_gen))\n",
    "        \n",
    "ru_gen = np.array([x.numpy() for x in ru_gen])\n",
    "ru_gen = ru_gen.squeeze()\n",
    "ru_gen.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./averages/ru_unc.npy', 'wb') as f:\n",
    "    np.save(f, ru_unc)\n",
    "    \n",
    "with open('./averages/ru_acc.npy', 'wb') as f:\n",
    "    np.save(f, ru_acc)\n",
    "    \n",
    "with open('./averages/ru_dat.npy', 'wb') as f:\n",
    "    np.save(f, ru_dat)\n",
    "    \n",
    "with open('./averages/ru_gen.npy', 'wb') as f:\n",
    "    np.save(f, ru_gen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Czech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nominative</th>\n",
       "      <th>genitive</th>\n",
       "      <th>dative</th>\n",
       "      <th>accusative</th>\n",
       "      <th>vocative</th>\n",
       "      <th>locative</th>\n",
       "      <th>instrumental</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rok</td>\n",
       "      <td>roka</td>\n",
       "      <td>roku</td>\n",
       "      <td>rok</td>\n",
       "      <td>roku</td>\n",
       "      <td>roku</td>\n",
       "      <td>rokem</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>člověk</td>\n",
       "      <td>člověka</td>\n",
       "      <td>člověku</td>\n",
       "      <td>člověka</td>\n",
       "      <td>člověče</td>\n",
       "      <td>člověku</td>\n",
       "      <td>člověkem</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>den</td>\n",
       "      <td>dne</td>\n",
       "      <td>dni</td>\n",
       "      <td>den</td>\n",
       "      <td>dne</td>\n",
       "      <td>dni</td>\n",
       "      <td>dnem</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>doba</td>\n",
       "      <td>doby</td>\n",
       "      <td>době</td>\n",
       "      <td>dobu</td>\n",
       "      <td>dobo</td>\n",
       "      <td>době</td>\n",
       "      <td>dobou</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dítě</td>\n",
       "      <td>dítěte</td>\n",
       "      <td>dítěti</td>\n",
       "      <td>dítě</td>\n",
       "      <td>dítě</td>\n",
       "      <td>dítěti</td>\n",
       "      <td>dítětem</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  nominative genitive   dative accusative vocative locative instrumental\n",
       "0        rok     roka     roku        rok     roku     roku        rokem\n",
       "1     člověk  člověka  člověku    člověka  člověče  člověku     člověkem\n",
       "2        den      dne      dni        den      dne      dni         dnem\n",
       "3       doba     doby     době       dobu     dobo     době        dobou\n",
       "4       dítě   dítěte   dítěti       dítě     dítě   dítěti      dítětem"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cz.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150\n",
      "300\n",
      "450\n",
      "600\n",
      "750\n",
      "900\n",
      "1050\n",
      "1200\n",
      "1350\n",
      "1500\n",
      "(1574, 768) (1574, 768) (1574, 768) (1574, 768) (1574, 768)\n"
     ]
    }
   ],
   "source": [
    "cz_nom = []\n",
    "cz_acc = []\n",
    "cz_gen = []\n",
    "cz_dat = []\n",
    "cz_loc = []\n",
    "\n",
    "\"\"\"\n",
    "for x in pl['uncased']:\n",
    "    \n",
    "    if len(x) < 20:\n",
    "        encoded_input_ru = tokenizer(x, return_tensors = 'tf')\n",
    "        output_ru = model(encoded_input_ru)\n",
    "\n",
    "        pl_unc.append(tf.reduce_mean(output_ru.last_hidden_state, axis = 1))\n",
    "\n",
    "        if len(pl_unc) % 150 == 0:\n",
    "            print(len(pl_unc))\n",
    "        \n",
    "pl_unc = np.array([x.numpy() for x in pl_unc])\n",
    "pl_unc = pl_unc.squeeze()\n",
    "pl_unc.shape\n",
    "\"\"\"\n",
    "\n",
    "for i, x in cz.iterrows():\n",
    "    \n",
    "    ei = tokenizer(x['nominative'], return_tensors = 'tf')\n",
    "    o = model(ei) \n",
    "    cz_nom.append(tf.reduce_mean(o.last_hidden_state, axis = 1))\n",
    "    \n",
    "    ei = tokenizer(x['accusative'], return_tensors = 'tf')\n",
    "    o = model(ei) \n",
    "    cz_acc.append(tf.reduce_mean(o.last_hidden_state, axis = 1))\n",
    "    \n",
    "    ei = tokenizer(x['genitive'], return_tensors = 'tf')\n",
    "    o = model(ei) \n",
    "    cz_gen.append(tf.reduce_mean(o.last_hidden_state, axis = 1))\n",
    "    \n",
    "    ei = tokenizer(x['dative'], return_tensors = 'tf')\n",
    "    o = model(ei) \n",
    "    cz_dat.append(tf.reduce_mean(o.last_hidden_state, axis = 1))\n",
    "    \n",
    "    ei = tokenizer(x['locative'], return_tensors = 'tf')\n",
    "    o = model(ei) \n",
    "    cz_loc.append(tf.reduce_mean(o.last_hidden_state, axis = 1))\n",
    "    \n",
    "    if len(cz_acc) % 150 == 0:\n",
    "        print(len(cz_acc))\n",
    "        \n",
    "        \n",
    "cz_nom = np.array([x.numpy() for x in cz_nom])\n",
    "cz_acc = np.array([x.numpy() for x in cz_acc])\n",
    "cz_gen = np.array([x.numpy() for x in cz_gen])\n",
    "cz_dat = np.array([x.numpy() for x in cz_dat])\n",
    "cz_loc = np.array([x.numpy() for x in cz_loc])\n",
    "\n",
    "cz_nom = cz_nom.squeeze()\n",
    "cz_acc = cz_acc.squeeze()\n",
    "cz_gen = cz_gen.squeeze()\n",
    "cz_dat = cz_dat.squeeze()\n",
    "cz_loc = cz_loc.squeeze()\n",
    "\n",
    "print(cz_nom.shape, cz_acc.shape, cz_gen.shape, cz_dat.shape, cz_loc.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./averages/cz_nom.npy', 'wb') as f:\n",
    "    np.save(f, cz_nom)\n",
    "    \n",
    "with open('./averages/cz_acc.npy', 'wb') as f:\n",
    "    np.save(f, cz_acc)\n",
    "    \n",
    "with open('./averages/cz_gen.npy', 'wb') as f:\n",
    "    np.save(f, cz_gen)\n",
    "    \n",
    "with open('./averages/cz_dat.npy', 'wb') as f:\n",
    "    np.save(f, cz_dat)\n",
    "    \n",
    "with open('./averages/cz_loc.npy', 'wb') as f:\n",
    "    np.save(f, cz_loc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finnish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Nominative</th>\n",
       "      <th>accusative_nom</th>\n",
       "      <th>accusative_gen</th>\n",
       "      <th>genitive</th>\n",
       "      <th>partitive</th>\n",
       "      <th>inessive</th>\n",
       "      <th>elative</th>\n",
       "      <th>illative</th>\n",
       "      <th>adessive</th>\n",
       "      <th>ablative</th>\n",
       "      <th>allative</th>\n",
       "      <th>essive</th>\n",
       "      <th>translative</th>\n",
       "      <th>abessive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vuosi</td>\n",
       "      <td>vuosi</td>\n",
       "      <td>vuoden</td>\n",
       "      <td>vuoden</td>\n",
       "      <td>vuotta</td>\n",
       "      <td>vuodessa</td>\n",
       "      <td>vuodesta</td>\n",
       "      <td>vuoteen</td>\n",
       "      <td>vuodella</td>\n",
       "      <td>vuodelta</td>\n",
       "      <td>vuodelle</td>\n",
       "      <td>vuotena</td>\n",
       "      <td>vuodeksi</td>\n",
       "      <td>vuodetta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>markka</td>\n",
       "      <td>markka</td>\n",
       "      <td>markan</td>\n",
       "      <td>markan</td>\n",
       "      <td>markkaa</td>\n",
       "      <td>markassa</td>\n",
       "      <td>markasta</td>\n",
       "      <td>markkaan</td>\n",
       "      <td>markalla</td>\n",
       "      <td>markalta</td>\n",
       "      <td>markalle</td>\n",
       "      <td>markkana</td>\n",
       "      <td>markaksi</td>\n",
       "      <td>markatta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>maa</td>\n",
       "      <td>maa</td>\n",
       "      <td>maan</td>\n",
       "      <td>maan</td>\n",
       "      <td>maata</td>\n",
       "      <td>maassa</td>\n",
       "      <td>maasta</td>\n",
       "      <td>maahan</td>\n",
       "      <td>maalla</td>\n",
       "      <td>maalta</td>\n",
       "      <td>maalle</td>\n",
       "      <td>maana</td>\n",
       "      <td>maaksi</td>\n",
       "      <td>maatta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>asia</td>\n",
       "      <td>asia</td>\n",
       "      <td>asian</td>\n",
       "      <td>asian</td>\n",
       "      <td>asiaa</td>\n",
       "      <td>asiassa</td>\n",
       "      <td>asiasta</td>\n",
       "      <td>asiaan</td>\n",
       "      <td>asialla</td>\n",
       "      <td>asialta</td>\n",
       "      <td>asialle</td>\n",
       "      <td>asiana</td>\n",
       "      <td>asiaksi</td>\n",
       "      <td>asiatta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>prosentti</td>\n",
       "      <td>prosentti</td>\n",
       "      <td>prosentin</td>\n",
       "      <td>prosentin</td>\n",
       "      <td>prosenttia</td>\n",
       "      <td>prosentissa</td>\n",
       "      <td>prosentista</td>\n",
       "      <td>prosenttiin</td>\n",
       "      <td>prosentilla</td>\n",
       "      <td>prosentilta</td>\n",
       "      <td>prosentille</td>\n",
       "      <td>prosenttina</td>\n",
       "      <td>prosentiksi</td>\n",
       "      <td>prosentitta</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Nominative accusative_nom accusative_gen   genitive   partitive  \\\n",
       "0      vuosi          vuosi         vuoden     vuoden      vuotta   \n",
       "1     markka         markka         markan     markan     markkaa   \n",
       "2        maa            maa           maan       maan       maata   \n",
       "3       asia           asia          asian      asian       asiaa   \n",
       "4  prosentti      prosentti      prosentin  prosentin  prosenttia   \n",
       "\n",
       "      inessive      elative     illative     adessive     ablative  \\\n",
       "0     vuodessa     vuodesta      vuoteen     vuodella     vuodelta   \n",
       "1     markassa     markasta     markkaan     markalla     markalta   \n",
       "2       maassa       maasta       maahan       maalla       maalta   \n",
       "3      asiassa      asiasta       asiaan      asialla      asialta   \n",
       "4  prosentissa  prosentista  prosenttiin  prosentilla  prosentilta   \n",
       "\n",
       "      allative       essive  translative     abessive  \n",
       "0     vuodelle      vuotena     vuodeksi     vuodetta  \n",
       "1     markalle     markkana     markaksi     markatta  \n",
       "2       maalle        maana       maaksi       maatta  \n",
       "3      asialle       asiana      asiaksi      asiatta  \n",
       "4  prosentille  prosenttina  prosentiksi  prosentitta  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fi.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150\n",
      "300\n",
      "450\n",
      "600\n",
      "750\n",
      "900\n",
      "1050\n",
      "1200\n",
      "1350\n",
      "1500\n",
      "1650\n",
      "1800\n",
      "1950\n",
      "(2050, 768) (2050, 768) (2050, 768) (2050, 768) (2050, 768)\n"
     ]
    }
   ],
   "source": [
    "# first 3, plus adessive and inessive\n",
    "fi_acc_n = []\n",
    "fi_acc_g = []\n",
    "fi_gen = []\n",
    "fi_ins = []\n",
    "fi_ads = []\n",
    "\n",
    "for i, x in fi.iterrows():\n",
    "    \n",
    "    ei = tokenizer(x['accusative_nom'], return_tensors = 'tf')\n",
    "    o = model(ei) \n",
    "    fi_acc_n.append(tf.reduce_mean(o.last_hidden_state, axis = 1))\n",
    "    \n",
    "    #print(x['accusative_nom'], o)\n",
    "    \n",
    "    ei = tokenizer(x['accusative_gen'], return_tensors = 'tf')\n",
    "    o = model(ei) \n",
    "    fi_acc_g.append(tf.reduce_mean(o.last_hidden_state, axis = 1))\n",
    "    \n",
    "    #print(x['accusative_gen'], o)\n",
    "    \n",
    "    ei = tokenizer(x['genitive'], return_tensors = 'tf')\n",
    "    o = model(ei) \n",
    "    fi_gen.append(tf.reduce_mean(o.last_hidden_state, axis = 1))\n",
    "    \n",
    "    ei = tokenizer(x['inessive'], return_tensors = 'tf')\n",
    "    o = model(ei) \n",
    "    fi_ins.append(tf.reduce_mean(o.last_hidden_state, axis = 1))\n",
    "    \n",
    "    ei = tokenizer(x['adessive'], return_tensors = 'tf')\n",
    "    o = model(ei) \n",
    "    fi_ads.append(tf.reduce_mean(o.last_hidden_state, axis = 1))\n",
    "    \n",
    "    \n",
    "    if len(fi_acc_n) % 150 == 0:\n",
    "        print(len(fi_acc_n))\n",
    "        \n",
    "        \n",
    "fi_acc_n = np.array([x.numpy() for x in fi_acc_n])\n",
    "fi_acc_g = np.array([x.numpy() for x in fi_acc_g])\n",
    "fi_gen = np.array([x.numpy() for x in fi_gen])\n",
    "fi_ins = np.array([x.numpy() for x in fi_ins])\n",
    "fi_ads = np.array([x.numpy() for x in fi_ads])\n",
    "\n",
    "fi_acc_n = fi_acc_n.squeeze()\n",
    "fi_acc_g = fi_acc_g.squeeze()\n",
    "fi_gen = fi_gen.squeeze()\n",
    "fi_ins = fi_ins.squeeze()\n",
    "fi_ads = fi_ads.squeeze()\n",
    "\n",
    "print(fi_acc_n.shape, fi_acc_g.shape, fi_gen.shape, fi_ins.shape, fi_ads.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./averages/fi_acc_n.npy', 'wb') as f:\n",
    "    np.save(f, fi_acc_n)\n",
    "    \n",
    "with open('./averages/fi_acc_g.npy', 'wb') as f:\n",
    "    np.save(f, fi_acc_g)\n",
    "    \n",
    "with open('./averages/fi_gen.npy', 'wb') as f:\n",
    "    np.save(f, fi_gen)\n",
    "    \n",
    "with open('./averages/fi_ins.npy', 'wb') as f:\n",
    "    np.save(f, fi_ins)\n",
    "    \n",
    "with open('./averages/fi_ads.npy', 'wb') as f:\n",
    "    np.save(f, fi_ads)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Polish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uncased</th>\n",
       "      <th>nominative</th>\n",
       "      <th>genitive</th>\n",
       "      <th>dative</th>\n",
       "      <th>accusative</th>\n",
       "      <th>instrumental</th>\n",
       "      <th>locative</th>\n",
       "      <th>vocative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mama</td>\n",
       "      <td>mama</td>\n",
       "      <td>mamy</td>\n",
       "      <td>mamie</td>\n",
       "      <td>mamę</td>\n",
       "      <td>mamą</td>\n",
       "      <td>mamie</td>\n",
       "      <td>mamo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pan</td>\n",
       "      <td>pan</td>\n",
       "      <td>pana</td>\n",
       "      <td>panu</td>\n",
       "      <td>pana</td>\n",
       "      <td>panem</td>\n",
       "      <td>panie</td>\n",
       "      <td>panie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>więc</td>\n",
       "      <td>wiec</td>\n",
       "      <td>wiecu</td>\n",
       "      <td>wiecowi</td>\n",
       "      <td>wiec</td>\n",
       "      <td>wiecem</td>\n",
       "      <td>wiecu</td>\n",
       "      <td>wiecu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pani</td>\n",
       "      <td>pani</td>\n",
       "      <td>pani</td>\n",
       "      <td>pani</td>\n",
       "      <td>panią</td>\n",
       "      <td>panią</td>\n",
       "      <td>pani</td>\n",
       "      <td>pani!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>żeby</td>\n",
       "      <td>ząb</td>\n",
       "      <td>zęba</td>\n",
       "      <td>zębowi</td>\n",
       "      <td>ząb</td>\n",
       "      <td>zębem</td>\n",
       "      <td>zębie</td>\n",
       "      <td>zębie</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  uncased nominative genitive   dative accusative instrumental locative  \\\n",
       "0    mama       mama     mamy    mamie       mamę         mamą    mamie   \n",
       "1     pan        pan     pana     panu       pana        panem    panie   \n",
       "2    więc       wiec    wiecu  wiecowi       wiec       wiecem    wiecu   \n",
       "3    pani       pani     pani     pani      panią        panią     pani   \n",
       "4    żeby        ząb     zęba   zębowi        ząb        zębem    zębie   \n",
       "\n",
       "  vocative  \n",
       "0     mamo  \n",
       "1    panie  \n",
       "2    wiecu  \n",
       "3    pani!  \n",
       "4    zębie  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pl.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150\n",
      "300\n",
      "450\n",
      "600\n",
      "750\n",
      "(816, 768) (816, 768) (816, 768) (816, 768) (816, 768) (816, 768)\n"
     ]
    }
   ],
   "source": [
    "pl_unc = []\n",
    "pl_nom = []\n",
    "pl_acc = []\n",
    "pl_gen = []\n",
    "pl_dat = []\n",
    "pl_loc = []\n",
    "\n",
    "for i, x in pl.iterrows():\n",
    "    \n",
    "    ei = tokenizer(x['uncased'], return_tensors = 'tf')\n",
    "    o = model(ei) \n",
    "    pl_unc.append(tf.reduce_mean(o.last_hidden_state, axis = 1))\n",
    "    \n",
    "    ei = tokenizer(x['nominative'], return_tensors = 'tf')\n",
    "    o = model(ei) \n",
    "    pl_nom.append(tf.reduce_mean(o.last_hidden_state, axis = 1))\n",
    "    \n",
    "    ei = tokenizer(x['accusative'], return_tensors = 'tf')\n",
    "    o = model(ei) \n",
    "    pl_acc.append(tf.reduce_mean(o.last_hidden_state, axis = 1))\n",
    "    \n",
    "    ei = tokenizer(x['genitive'], return_tensors = 'tf')\n",
    "    o = model(ei) \n",
    "    pl_gen.append(tf.reduce_mean(o.last_hidden_state, axis = 1))\n",
    "    \n",
    "    ei = tokenizer(x['dative'], return_tensors = 'tf')\n",
    "    o = model(ei) \n",
    "    pl_dat.append(tf.reduce_mean(o.last_hidden_state, axis = 1))\n",
    "    \n",
    "    ei = tokenizer(x['locative'], return_tensors = 'tf')\n",
    "    o = model(ei) \n",
    "    pl_loc.append(tf.reduce_mean(o.last_hidden_state, axis = 1))\n",
    "    \n",
    "    \n",
    "    if len(pl_loc) % 150 == 0:\n",
    "        print(len(pl_loc))\n",
    "        \n",
    "        \n",
    "pl_unc = np.array([x.numpy() for x in pl_unc])\n",
    "pl_nom = np.array([x.numpy() for x in pl_nom])\n",
    "pl_acc = np.array([x.numpy() for x in pl_acc])\n",
    "pl_gen = np.array([x.numpy() for x in pl_gen])\n",
    "pl_dat = np.array([x.numpy() for x in pl_dat])\n",
    "pl_loc = np.array([x.numpy() for x in pl_loc])\n",
    "\n",
    "pl_unc = pl_unc.squeeze()\n",
    "pl_nom = pl_nom.squeeze()\n",
    "pl_acc = pl_acc.squeeze()\n",
    "pl_gen = pl_gen.squeeze()\n",
    "pl_dat = pl_dat.squeeze()\n",
    "pl_loc = pl_loc.squeeze()\n",
    "\n",
    "print(pl_unc.shape, pl_nom.shape, pl_acc.shape, pl_gen.shape, pl_dat.shape, pl_loc.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./averages/pl_unc.npy', 'wb') as f:\n",
    "    np.save(f, pl_unc)\n",
    "    \n",
    "with open('./averages/pl_nom.npy', 'wb') as f:\n",
    "    np.save(f, pl_nom)\n",
    "    \n",
    "with open('./averages/pl_acc.npy', 'wb') as f:\n",
    "    np.save(f, pl_acc)\n",
    "    \n",
    "with open('./averages/pl_gen.npy', 'wb') as f:\n",
    "    np.save(f, pl_gen)\n",
    "    \n",
    "with open('./averages/pl_dat.npy', 'wb') as f:\n",
    "    np.save(f, pl_dat)\n",
    "    \n",
    "with open('./averages/pl_loc.npy', 'wb') as f:\n",
    "    np.save(f, pl_loc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## deutsch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>noun</th>\n",
       "      <th>lemma</th>\n",
       "      <th>pos</th>\n",
       "      <th>genus</th>\n",
       "      <th>genitiv singular</th>\n",
       "      <th>genitiv plural</th>\n",
       "      <th>dativ singular</th>\n",
       "      <th>dativ plural</th>\n",
       "      <th>akkusativ singular</th>\n",
       "      <th>akkusativ plural</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sie</td>\n",
       "      <td>Sie</td>\n",
       "      <td>Substantiv</td>\n",
       "      <td>f</td>\n",
       "      <td>Sie</td>\n",
       "      <td>Sie</td>\n",
       "      <td>Sie</td>\n",
       "      <td>Sie</td>\n",
       "      <td>Sie</td>\n",
       "      <td>Sie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sie</td>\n",
       "      <td>Sie</td>\n",
       "      <td>Substantiv</td>\n",
       "      <td>m</td>\n",
       "      <td>Sies</td>\n",
       "      <td>Sie</td>\n",
       "      <td>Sie</td>\n",
       "      <td>Sies</td>\n",
       "      <td>Sie</td>\n",
       "      <td>Sies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Es</td>\n",
       "      <td>Es</td>\n",
       "      <td>Substantiv</td>\n",
       "      <td>n</td>\n",
       "      <td>Es</td>\n",
       "      <td>Es</td>\n",
       "      <td>Es</td>\n",
       "      <td>Es</td>\n",
       "      <td>Es</td>\n",
       "      <td>Es</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Er</td>\n",
       "      <td>Er</td>\n",
       "      <td>Substantiv</td>\n",
       "      <td>m</td>\n",
       "      <td>Er</td>\n",
       "      <td>Er</td>\n",
       "      <td>Er</td>\n",
       "      <td>Er</td>\n",
       "      <td>Er</td>\n",
       "      <td>Er</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Zeit</td>\n",
       "      <td>Zeit</td>\n",
       "      <td>Substantiv</td>\n",
       "      <td>f</td>\n",
       "      <td>Zeit</td>\n",
       "      <td>Zeiten</td>\n",
       "      <td>Zeit</td>\n",
       "      <td>Zeiten</td>\n",
       "      <td>Zeit</td>\n",
       "      <td>Zeiten</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3538</th>\n",
       "      <td>Apotheke</td>\n",
       "      <td>Apotheke</td>\n",
       "      <td>Substantiv</td>\n",
       "      <td>f</td>\n",
       "      <td>Apotheke</td>\n",
       "      <td>Apotheken</td>\n",
       "      <td>Apotheke</td>\n",
       "      <td>Apotheken</td>\n",
       "      <td>Apotheke</td>\n",
       "      <td>Apotheken</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3539</th>\n",
       "      <td>Wood</td>\n",
       "      <td>Wood</td>\n",
       "      <td>Substantiv</td>\n",
       "      <td>m</td>\n",
       "      <td>Woods</td>\n",
       "      <td>Woods</td>\n",
       "      <td>Wood</td>\n",
       "      <td>Woods</td>\n",
       "      <td>Wood</td>\n",
       "      <td>Woods</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3540</th>\n",
       "      <td>Wecker</td>\n",
       "      <td>Wecker</td>\n",
       "      <td>Substantiv</td>\n",
       "      <td>m</td>\n",
       "      <td>Weckers</td>\n",
       "      <td>Wecker</td>\n",
       "      <td>Wecker</td>\n",
       "      <td>Weckern</td>\n",
       "      <td>Wecker</td>\n",
       "      <td>Wecker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3542</th>\n",
       "      <td>Unterwelt</td>\n",
       "      <td>Unterwelt</td>\n",
       "      <td>Substantiv</td>\n",
       "      <td>f</td>\n",
       "      <td>Unterwelt</td>\n",
       "      <td>Unterwelten</td>\n",
       "      <td>Unterwelt</td>\n",
       "      <td>Unterwelten</td>\n",
       "      <td>Unterwelt</td>\n",
       "      <td>Unterwelten</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3543</th>\n",
       "      <td>Union</td>\n",
       "      <td>Union</td>\n",
       "      <td>Substantiv</td>\n",
       "      <td>f</td>\n",
       "      <td>Union</td>\n",
       "      <td>Unionen</td>\n",
       "      <td>Union</td>\n",
       "      <td>Unionen</td>\n",
       "      <td>Union</td>\n",
       "      <td>Unionen</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2369 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           noun      lemma         pos genus genitiv singular genitiv plural  \\\n",
       "1           Sie        Sie  Substantiv     f              Sie            Sie   \n",
       "2           Sie        Sie  Substantiv     m             Sies            Sie   \n",
       "6            Es         Es  Substantiv     n               Es             Es   \n",
       "8            Er         Er  Substantiv     m               Er             Er   \n",
       "17         Zeit       Zeit  Substantiv     f             Zeit         Zeiten   \n",
       "...         ...        ...         ...   ...              ...            ...   \n",
       "3538   Apotheke   Apotheke  Substantiv     f         Apotheke      Apotheken   \n",
       "3539       Wood       Wood  Substantiv     m            Woods          Woods   \n",
       "3540     Wecker     Wecker  Substantiv     m          Weckers         Wecker   \n",
       "3542  Unterwelt  Unterwelt  Substantiv     f        Unterwelt    Unterwelten   \n",
       "3543      Union      Union  Substantiv     f            Union        Unionen   \n",
       "\n",
       "     dativ singular dativ plural akkusativ singular akkusativ plural  \n",
       "1               Sie          Sie                Sie              Sie  \n",
       "2               Sie         Sies                Sie             Sies  \n",
       "6                Es           Es                 Es               Es  \n",
       "8                Er           Er                 Er               Er  \n",
       "17             Zeit       Zeiten               Zeit           Zeiten  \n",
       "...             ...          ...                ...              ...  \n",
       "3538       Apotheke    Apotheken           Apotheke        Apotheken  \n",
       "3539           Wood        Woods               Wood            Woods  \n",
       "3540         Wecker      Weckern             Wecker           Wecker  \n",
       "3542      Unterwelt  Unterwelten          Unterwelt      Unterwelten  \n",
       "3543          Union      Unionen              Union          Unionen  \n",
       "\n",
       "[2369 rows x 10 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "de"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['noun', 'lemma', 'pos', 'genus', 'genitiv singular', 'genitiv plural',\n",
       "       'dativ singular', 'dativ plural', 'akkusativ singular',\n",
       "       'akkusativ plural'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "de.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150\n",
      "300\n",
      "450\n",
      "600\n",
      "750\n",
      "900\n",
      "1050\n",
      "1200\n",
      "1350\n",
      "1500\n",
      "1650\n",
      "1800\n",
      "1950\n",
      "2100\n",
      "2250\n",
      "(2369, 768) (2369, 768) (2369, 768) (2369, 768)\n"
     ]
    }
   ],
   "source": [
    "de_unc = []\n",
    "de_gen = []\n",
    "de_dat = []\n",
    "de_acc = []\n",
    "\n",
    "for i, x in de.iterrows():\n",
    "    \n",
    "    if x['genus'] == 'm':\n",
    "        ei = tokenizer(\"der \" + x['noun'], return_tensors = 'tf')\n",
    "        o = model(ei) \n",
    "        de_unc.append(tf.reduce_mean(o.last_hidden_state, axis = 1))\n",
    "        \n",
    "        ei = tokenizer(\"des \" + x['genitiv singular'], return_tensors = 'tf')\n",
    "        o = model(ei) \n",
    "        de_gen.append(tf.reduce_mean(o.last_hidden_state, axis = 1))\n",
    "        \n",
    "        ei = tokenizer(\"dem \" + x['dativ singular'], return_tensors = 'tf')\n",
    "        o = model(ei) \n",
    "        de_dat.append(tf.reduce_mean(o.last_hidden_state, axis = 1))\n",
    "        \n",
    "        ei = tokenizer(\"den \" + x['akkusativ singular'], return_tensors = 'tf')\n",
    "        o = model(ei) \n",
    "        de_acc.append(tf.reduce_mean(o.last_hidden_state, axis = 1))\n",
    "    \n",
    "    elif x['genus'] == 'f':\n",
    "        ei = tokenizer(\"die \" + x['noun'], return_tensors = 'tf')\n",
    "        o = model(ei) \n",
    "        de_unc.append(tf.reduce_mean(o.last_hidden_state, axis = 1))\n",
    "        \n",
    "        ei = tokenizer(\"der \" + x['genitiv singular'], return_tensors = 'tf')\n",
    "        o = model(ei) \n",
    "        de_gen.append(tf.reduce_mean(o.last_hidden_state, axis = 1))\n",
    "        \n",
    "        ei = tokenizer(\"der \" + x['dativ singular'], return_tensors = 'tf')\n",
    "        o = model(ei) \n",
    "        de_dat.append(tf.reduce_mean(o.last_hidden_state, axis = 1))\n",
    "        \n",
    "        ei = tokenizer(\"die \" + x['akkusativ singular'], return_tensors = 'tf')\n",
    "        o = model(ei) \n",
    "        de_acc.append(tf.reduce_mean(o.last_hidden_state, axis = 1))\n",
    "        \n",
    "    elif x['genus'] == 'n':\n",
    "        ei = tokenizer(\"das \" + x['noun'], return_tensors = 'tf')\n",
    "        o = model(ei) \n",
    "        de_unc.append(tf.reduce_mean(o.last_hidden_state, axis = 1))\n",
    "        \n",
    "        ei = tokenizer(\"des \" + x['genitiv singular'], return_tensors = 'tf')\n",
    "        o = model(ei) \n",
    "        de_gen.append(tf.reduce_mean(o.last_hidden_state, axis = 1))\n",
    "        \n",
    "        ei = tokenizer(\"dem \" + x['dativ singular'], return_tensors = 'tf')\n",
    "        o = model(ei) \n",
    "        de_dat.append(tf.reduce_mean(o.last_hidden_state, axis = 1))\n",
    "        \n",
    "        ei = tokenizer(\"das \" + x['akkusativ singular'], return_tensors = 'tf')\n",
    "        o = model(ei) \n",
    "        de_acc.append(tf.reduce_mean(o.last_hidden_state, axis = 1))\n",
    "        \n",
    "    if len(de_gen) % 150 == 0:\n",
    "        print(len(de_gen))\n",
    "\n",
    "de_unc = np.array([x.numpy() for x in de_unc])\n",
    "de_gen = np.array([x.numpy() for x in de_gen])\n",
    "de_dat = np.array([x.numpy() for x in de_dat])\n",
    "de_acc = np.array([x.numpy() for x in de_acc])\n",
    "\n",
    "de_unc = de_unc.squeeze()\n",
    "de_gen = de_gen.squeeze()\n",
    "de_dat = de_dat.squeeze()\n",
    "de_acc = de_acc.squeeze()\n",
    "\n",
    "print(de_unc.shape, de_gen.shape, de_dat.shape, de_acc.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./averages/de_unc.npy', 'wb') as f:\n",
    "    np.save(f, de_unc)\n",
    "    \n",
    "with open('./averages/de_gen.npy', 'wb') as f:\n",
    "    np.save(f, de_gen)\n",
    "    \n",
    "with open('./averages/de_dat.npy', 'wb') as f:\n",
    "    np.save(f, de_dat)\n",
    "    \n",
    "with open('./averages/de_acc.npy', 'wb') as f:\n",
    "    np.save(f, de_acc)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
